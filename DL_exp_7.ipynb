{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "06e03c016b56472fa2ddd693bae1a48e",
      "7717a942d0654387b4acb503f5a3a8f3",
      "4078071fc21a494a9bd027383f6126e4",
      "dd0a457292304ee8b75b9203cd0fd87a",
      "4654ec72b015421b92a4a59c5bd97007",
      "61aff14325c8444784d0c437a4dda032",
      "6b2edc1e55c4455790446d8075d20049",
      "f315e3c605d7429c893042dafa4e21de",
      "1a48c9d647b0461eaba4a101502e7f05",
      "9785dcdf2d074c0c9a00b14baa7bb2a6",
      "1177b3306a76467da49ddc5da644b8ff"
     ]
    },
    "id": "5slTU11GClz-",
    "outputId": "bc2abf7f-e579-4b89-ce5b-790b08091b18"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e03c016b56472fa2ddd693bae1a48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: a cat sitting on the floor next to a rug \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from PIL import Image\n",
    "from transformers.utils import hub\n",
    "\n",
    "hub.HUGGINGFACE_HUB_HTTP_TIMEOUT = 60\n",
    "\n",
    "# Load model\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "processor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Caption generation\n",
    "def generate_caption(image_path, max_length=30, num_beams=4):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    output_ids = model.generate(pixel_values, max_length=max_length, num_beams=num_beams, early_stopping=True)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Generate caption\n",
    "if __name__ == \"__main__\":\n",
    "    img_path = \"/content/cat-1.jpeg\"  # Replace with your image\n",
    "    print(\"Caption:\", generate_caption(img_path))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
